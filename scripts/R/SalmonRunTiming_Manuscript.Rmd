---
title: "Runtiming - Four Species Data Compilation"
author: "Natasha Howe"
date: format(Sys.Date(), "%Y/%m/%d")
output: 
  html_document:
    keep_md: true
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#load libraries
library(tidyverse)
```

The fourspecies data compiled the separate R project data for Auke Creek pink, Wood River sockeye, Yukon River chum, and Skilak River coho.

## Introduction

Investigating run timing differentiation between early and late returning salmon from multiple regions of Alaska. All species were aligned to chum to compare the specified regions on the genome that are differentiated across species.

## Sample Collection

Sample collection data was compiled from the raw data in each four species manually with three columns: sampleID, Runtime, and Species

```{r MetaData, eval=F, echo=T}
# All samples and sequencing information can be found at:
read.csv("./data/raw/fourspecies_runtiming_metadata.csv")
```

## Whole Genome Sequencing

Sequencing facilities differed across samples and had vastly different coverages. Refer to methods for species-specific sequencing effort details.

### Step 0: Setup

PREFIX below can be substituted depending on the species comparison being looked at: For example:

Prefix Options:

1.  **Chum (Yukon):** "chumrun"
2.  **Coho (Skilak Lake):** "coho-chum"
3.  **Sockeye**:
    i.  **Teal (Early Creek) and Whitefish (Late Creek)**: "sock-chum"
    ii. **Teal (Early Creek) and Anvil (Late Beach)**: "euclide"
    iii. **Teal (Early Creek) and Whitefish (Late Creek) and Anvil (Late Beach)**: "sock-all"
4.  **Pink:**
    i.  **Even**: "pink-chum"
    ii. **Odd**: "pink-odd

The first thing we did is download a reference genome onto our Slurm Manager so that we can align our data. We are using the *chum salmon* reference genome version 2.

We can make a list of chromosomes by using a few commands in the terminal. All the chromosome lines start with NC, so we can use grep to find lines that start with (\^) the characters '\>NC' and pass those lines to awk to print the first column (\$1) and pass that to sed to remove the character '\>' that begins each line. We should have a text file with all the chromosome names.

```{bash Chromosomes, eval=F, echo=T}
grep '^>NC' ./home/nhowe/reference_genomes/chum/GCF_023373465.1_Oket_V2_genomic.fna |  awk '{print $1}' | sed 's/>//' > chromosomes_all.txt
```

Chum have 37 chromosomes + 1 mtDNA. LRRC9 is on Chr 35.

Note that if you use the Genbank file you will have to replace NC with CM in the grep argument. Sometimes the mitochondrial genome is not present in the GCA file but is in the GCF file so you may have to omit it from our list of chromosomes to analyze.

```{r RmMtDNA, eval=F, echo=T}
sed '/NC_017838.1/d' chromosomes_all.txt > chromosomes.txt
```

Get sizes of chromosomes

```{bash ChromSize, eval=F, echo=T}
 cut -f1,2 GCF_023373465.1_Oket_V2_genomic.fna.fai | grep '^NC' > chrom_sizes.txt
```

Two shell scripts index the reference genome and can be run with the sbatch command which will have the SLURM manager schedule them.

```{bash, Step0_bwa_fai, eval=F, echo=T}
sbatch GCF_023373465.1_Oket_V2_genomic_bwa-index_script.sh
sbatch GCF_023373465.1_Oket_V2_genomic_fai_script.sh
```

### Step 1: Quality Control

This step is a quality control of the sequencing data (raw fastqs). It runs FastQC [@Andrews2010] on the raw sequence data. FastQC is a java based application that runs a set of quality control measures.

-   Import data from BAM, SAM or FastQ files (any variant)
-   Provides a quick overview indicating in which areas there may be problems
-   Summary graphs and tables to quickly assess data quality
-   Export of results to an HTML based permanent report
-   Offline operation to allow automated generation of reports without running the interactive application

Run two shell scripts [PREFIX]-raw_fastqcARRAY.sh and [PREFIX]-raw_multiqcSLURM.sh in succession.

```{bash, Step1_multiqc, eval=F, echo = T}
sbatch [PREFIX]-raw_fastqcARRAY.sh
sbatch [PREFIX]-raw_multiqcSLURM.sh
```

### Step 2: Trim

Trim adapters from raw fastqs with the program TRIMMOMATIC [@Bolger2014] and quality-check the trimmed fastqs with multiQC [@Ewels2016]. Run three shell scripts [PREFIX]\_trimARRAY.sh, [PREFIX]-trim_fastqcARRAY.sh, and [PREFIX]-trim_multiqcSLURM.sh which should all run in succession.

```{bash, Step2_Trim, eval=F, echo=T}
# trim adapters
sbatch [PREFIX]_trimARRAY.sh

# multiqc report
sbatch [PREFIX]-trim_fastqcARRAY.sh
sbatch [PREFIX]-trim_multiqcSLURM.sh
```

Download the multiQC.html file and evaluate the data quality before proceeding.

### Step 3: Align

Align reads to the reference genome that we downloaded with BWA and runs the aligned reads through SAMTOOLS [@Li2009]: 'fixmate' cleans up the read pairings and flags from BWA; a pair of 'view' statements converts the .sam file to a .bam file and filters the .bam file for non-unique and poor quality mappings; and 'sort' sorts the read pairings by coordinate (instead of read name). After a .bam file is built, duplicate reads are removed and (if the data is PE) overlapping reads are clipped to generate the final .bam.

```{bash, Step3_Align, eval=F, echo=T}
# align to genome
sbatch [PREFIX]_alignARRAY.sh

# calculate average depths
sbatch [PREFIX]_depthsARRAY.sh
```

There is an output file [PREFIX]\_depths.csv which we can import and run through the downsampling script to see if there is uneven distribution of depths across early and late individuals. The depth of these samples were quite low, and we didn't even use a cutoff because the two individuals that were less than 0.5x were in the 0.4s.

```{R, plotDepths, eval=F, echo=T}
downsampling_[PREFIX].R
```

#### Mapped Reads

Calculate the total number of mapped reads from the bamfiles with samtools.

```{bash, mappedReads, eval=F, echo=T}
sbatch [PREFIX]_mapped_reads.sh
```

Now calculate the average and standard deviation for the mapped reads after downloading.

```{r, mapped_reads, eval=F, echo=T}
mean(read.csv("./results/depth/[PREFIX]_mapped_reads.csv", header = F)$V1)
sd(read.csv("./results/depth/[PREFIX]_mapped_reads.csv", header = F)$V1)
```

### Step 4: Genotype Likelihoods

Calculates genotype likelihoods for putatively polymorphic sites and all sites. This is done on a chrom-by-chrom level using an array. Both of these scripts use [PREFIX]\_angsdARRAY_input.txt (array file with chromosomes) and a list of the bam files to analyze (non-blocklist files -filtered_bamslist.txt).

```{bash, Step4_LikelihoodCalc, eval=F, echo=T}
sbatch [PREFIX]_minInd0.3_[minDepthHalf_]glsARRAY.sh 
```

Filters slightly differed depending on the species alignment and average coverage.

-   *minMapQ* [15]: the minimum map quality is 15, which was lowered from 20 for all except chum to allow for additional mis-alignments due to aligning to a different species.
-   *minQ* [20]: the minimum quality of nucleotide call is 20.
-   *C* [50]: use an adjustment of the Map Quality for excessive mismatches of 50. This is the suggested value for BWA and leads to fewer false positive variant calls.
-   *minDepth* [0.5\*N] or *minDepth* [N]: the minimum depth is set the number of individuals if average depth \> 1 and to half the number of individuals if avg depth was \< 1. Discard site if total sequencing depth (all individuals added together) is below minDepth.
-   *setMaxDepth* [20\*minDepth]: maximum depth is set to the number of individuals times 10 or 20. Discard site if total sequencing depth (all individuals added together) is above the number of individuals multiplied by 10 or 20 depending on the average depth of coverage.
-   *SNP_pval* [1e-10]: only work with sites with a p-value from the likelihood test of less than 1e-10.
-   *Gl* [1]: use SAMtools genotype likelihood calling algorithm. One assumption of the SAMtools algorithm is that it assumes that errors are not independent, but that once a first error occurs at a certain site in an individual, a second error is more likely to occur at the same site.
-   *minMaf* [0.05]: only work with sites with a maf above 0.05.
-   *minInd* [0.3\*N]: Set to 30% of sample size to include a proportion of individuals.
-   Additional Filters: *only_proper_pairs* [1]; *remove_bads* [1]; *uniqueOnly* [1]; *trim* [0]; *doMajorMinor* [1]

### Step 5: Collate

The genotype likelihood files from above are split by chromosome. Create whole genome beagle and maf files as well as a *sites* file that will be used as input for Fst calculations.

```{bash, Step5-collate, eval=F, echo=T}
# Again, copy and edit new files, including the output name
sbatch [PREFIX]_concat_minInd0.3_minDepthHalf_mafs.sh
sbatch [PREFIX]_concat_minInd0.3_minDepthHalf_beagles.sh
```

### Step 6: Population Analyses - FST

Created Bamlists for the early and late run timing phenotypes.

Move file to Slurm Manager scripts folder. The python script creates a bamlist for each group, and the shell script contains every combination of comparisons for FST. First, angsd calls GLs for each subgroup, but it uses the *sites* flag from the file created in Step 5, so the SNPs being called will be the same as for the polymorphic files from Step 4. Therefore, some of the filtering steps have been removed, such as: *SNP_pval* and *minMaf*.

*setminDepth* and set*maxDepth* are included, but adjusted to the sample size of the group. Added minInd to 30%, minDepth to half, maxDepth to 10\* and minMapQ to 20.

```{bash, fst, eval=F, echo=T}
# change name to better explain the Fst run
sbatch [PREFIX]_fst_fall-summer_minInd0.3_minDepthHalf_ARRAY.sh
```

## Identifying Regions of Divergence associated with Run Timing

Multi-species whole genome Fst scan plot with esrb and lrrc9 highlighted. These plots are the initial runtiming phenotype comparisons.

1.  Pink (Even): Early v. Late

2.  Sockeye: Early Creek v. Late Beach

3.  Chum: Early (Summer) v. Late (Fall)

4.  Coho: Early v. Late

```{r WG_fst, eval=F, echo=T}
Figure1_Fst_WholeGenomeManhattan_FourSpp.R
```

The two other comparisons were included in the supplementals.

5.  Pink (Odd): Early v. Late

6.  Sockeye: Early Creek v. Late Creek

```{r WG_fst_additional, eval=F, echo=T}
FigureS2_Fst_WholeGenomeManhattan_OddPink-Sockeye.R
```

The two highlighted regions of divergence that were shared across 2+ species were *lrrc9* and *esrb*. They are in the same \~850 kb duplicated region across chromosomes 29 and 35. To better visualize the two genes and the surrounding regions, they were plotted.

```{r, WGD_plot, eval=F, echo=T}
Figure2_A_WGD_Illustration.R
```

The gene/duplicate comparisons were imported into Inkscape and further developed into an illustration for the manuscript.

#### Consensus Tree

First, NCBI sequences were taken for lrrc9, esrb, and their duplicated variants (lrrc9-like, and esrb-like) from reference genomes in the four salmon species included in this study. They were imported into Geneious Prime and phylogenetic trees were created and exported as newick files.

Consensus trees were plotted for lrrc9 and esrb using the code below.

```{r, consensus_tree_plot, eval=F, echo=T}
Figure2_BC_ConsensusTrees.R
```

#### PCAs decide alleles

Barplots of putative allele proportions from PCA assignment of allele groups.

```{r alleleBarplot, eval=F, echo=T}
lrrc9_esrb_barplots.R
```

Local Fst figure for lrrc9 region with genes for pink, sockeye, & chum.

```{r lrrc9_fst, eval=F, echo=T}
threespp_lrrc9_fst_manhattan.R
```

Local Fst figure for esrb region with genes for coho and chum.

```{r esrb_fst, eval=F, echo=T}
twospp_esrb_fst_manhattan.R
```

### Allele-Based Neighbor Joining Tree

All of the bam files were already created at this point but are stored in the species-specific runtiming folders. Therefore, the species bamlists have to be concatenated.

```{bash bamslist, eval=F, echo=T}
cd runtiming/

cat ./pink/pink-chum_filtered_bamslist.txt ./sockeye/sock-chum_filtered_bamslist.txt ./coho/coho-chum_filtered_bamslist.txt ./[SPECIESDIR]/[PREFIX]_bamslist.txt > ./fourspecies/fourspp_bamslist.txt
```

This results in 405 total individuals.

Because the bam files are already created and in different folders, the pipeline wasn't directly used, but rather the output shell scripts from the other species were edited to reflect the current data.

Steps 1 - 3 of the pipeline were skipped and moved directly to calling GLs.

### Allele-based PCAs & FST

Whole genome combined. Again, just compiling data from different species into a single figure. Lrrc9 and Esrb was for the specific species in which there was a genetic association.

```{bash LocalpcAngsd, eval=F, echo=T}
sbatch lrrc9_pca_minInd0.3.sh
sbatch esrb_expand_pca_minInd0.3.sh # expand = broader than exact esrb gene boundary
```

Plotted each species-gene local PCA independently. In each of the R scripts, a
local PCA was plotted, where the PC1 showed variance across runtiming phenotypes.
Each local PCA was split into three clusters along the PC1 axis. The three groups
were defined as the homozygous early (EE), heterozygous (EL), and homozygous late (LL). 
```{r local_pca_fst, eval=F, echo=T}
../species_specific/[PREFIX]_lrrc9_pca.R
../species_specific/[PREFIX]_esrb_pca.R
```
The scripts above also split the individuals by sampleID into these three genotypes. Heterozygous individuals were dropped, and EE and LL individuals were placed into separate bamlists. 
The bamslists were used to run an allele-based FST, which was done in the scripts below.

```{bash LocalAlleleFst, eval=F, echo=T}
sbatch [PREFIX]_minInd0.3_lrrc9_allele_fst.sh
sbatch [PREFIX]_minInd0.3_esrb_allele_fst.sh
```

These figures are for the zoomed in FST on the main regions of differentiation using the pca-assigned genotypes. Genes within the regions are also included.

```{r local_pca_fst, eval=F, echo=T}
Figure3_Allele_LocalPCAandFst.R
```

Supplemental local PCAs - adding Whitefish to the local lrrc9 sockeye PCA, and Pink Odd lineage local PCA.

```{r local_pca_fst, eval=F, echo=T}
FigureS3_AlleleLocalPCAs_OddPink-Sockeye.R
```

### Phylogenetic Trees

Use the IBS matrix in angsd to create phylogenetic trees from our GL data. This was used within the lrrc9 gene region and the esrb gene region. The associated new and older flags include:

-   -doCov 1, -makeMatrix 1, & -doIBS 1

-   *minMapQ* [20]: the minimum map quality is 20.

-   *minQ* [20]: the minimum base quality is 20.

-   *doMajorMinor* [4]: Set the major and minor as the reference genome major/minor, was changed from 1.

-   *C* [50]: use an adjustment of the Map Quality for excessive mismatches of 50. This is the suggested value for BWA and leads to fewer false positive variant calls

-   *SNP_pval* [1e-10]: only work with sites with a p-value from the likelihood test of less than 1e-10.

-   *GL* [1]: use SAMtools genotype likelihood calling algorithm. One assumption of the SAMtools algorithm is that it assumes that errors are not independent, but that once a first error occurs at a certain site in an individual, a second error is more likely to occur at the same site

-   *minMaf* [0.05]: only work with sites with a maf above 0.05

#### Allele Trees

We used a subset of the total individuals assigned to homozygous early and late genotypes to plot a digestable phylogenetic tree for the manuscript (ten per species, 5 per allele group where applicable). Individuals were selected largely based on depth, as determined via the following script:

```{r top10Ind_Selection, eval=F, echo=T}
Individual_Subset_for_Figure4_AlleleNJTree.R
```

The script results in the following two files:

```         
fourspp_lrrc9_top5_ibs_input.txt
fourspp_esrb_top5_ibs_input.txt
```

Upload the files to Slurm Manager and use as input bamslists in the following shells.

```{bash top5_tree, eval=F, echo=T}
top5_lrrc9_fourspp_ibs.sh
top5_esrb_expand_fourspp_ibs.sh
```

Plot Trees in R for both lrrc9 and esrb.

```{r, tree_plot, eval=F, echo=T}
Figure4_AlleleNJTree.R
```
